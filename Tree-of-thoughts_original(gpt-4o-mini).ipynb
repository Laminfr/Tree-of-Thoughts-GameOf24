{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tree of Thoughts",
   "id": "cad96e63d6bf1035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> **Note:**\n",
    "> The code used in this notebook is adapted from the official LangGraph tutorial:\n",
    "> [https://langchain-ai.github.io/langgraph/tutorials/tot/tot/](https://langchain-ai.github.io/langgraph/tutorials/tot/tot/)\n",
    ">\n",
    "> It demonstrates an application of the **Tree of Thoughts** concept, originally introduced in the following research paper:\n",
    "> [Tree of Thoughts: Deliberate Problem Solving with Large Language Models (arXiv:2305.10601)](https://arxiv.org/abs/2305.10601)\n"
   ],
   "id": "77d1666620fe785d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:22.765763Z",
     "start_time": "2025-07-02T22:30:22.759509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os, getpass\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "#\n",
    "# _set_env(\"OPENAI_API_KEY\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:22.837397Z",
     "start_time": "2025-07-02T22:30:22.816082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "1cc972a8f7b68dc9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task Definition\n",
    "\n",
    "Our agent will try to play the **\"Game of 24\"**. Given 4 numbers, it must generate a math equation that uses each of these numbers exactly one time to evaluate to a value of 24.\n"
   ],
   "id": "cfe1891507ff09a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:23.317237Z",
     "start_time": "2025-07-02T22:30:22.959030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import operator\n",
    "from typing import List, Literal, Union, NamedTuple, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "OperatorType = Literal[\"+\", \"-\", \"*\", \"/\"]\n",
    "TokenType = Union[float, OperatorType]\n",
    "\n",
    "## We use these schemas to prompt the LLM to generate equations that evaluate to 24.\n",
    "\n",
    "\n",
    "class Equation(BaseModel):\n",
    "    \"\"\"The formula combining the provided numbers to reach the target of 24.\"\"\"\n",
    "\n",
    "    tokens: List[TokenType] = Field(\n",
    "        description=\"The stack of tokens and operators in reverse-polish notation. Example: [3, 4, '+', -1, '*'] would evaluate to (3 + 4) * -1 = -7.\",\n",
    "    )\n",
    "\n",
    "    def compute(self) -> float:\n",
    "        op_funcs = {\n",
    "            \"+\": operator.add,\n",
    "            \"-\": operator.sub,\n",
    "            \"*\": operator.mul,\n",
    "            \"/\": operator.truediv,\n",
    "        }\n",
    "        stack = []\n",
    "        for token in self.tokens:\n",
    "            if isinstance(token, float):\n",
    "                stack.append(token)\n",
    "            else:\n",
    "                b, a = stack.pop(), stack.pop()\n",
    "                stack.append(op_funcs[token](a, b))\n",
    "\n",
    "        return stack[0]\n",
    "\n",
    "\n",
    "class GuessEquations(BaseModel):\n",
    "    \"\"\"Submit multiple equations as guesses.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"The reasoning behind the submitted guesses. Explain how you arrived at these equations.\"\n",
    "    )\n",
    "\n",
    "    equations: List[Equation] = Field(\n",
    "        description=\"The list of equations to submit as guesses.\"\n",
    "    )\n",
    "\n",
    "\n",
    "## These objects will represent a single \"candidate\" (or scored candidate) within our agent's state.\n",
    "# You can update the candidate object to match your own task.\n",
    "\n",
    "\n",
    "class Candidate(NamedTuple):\n",
    "    candidate: Equation\n",
    "    score: Optional[float] = None\n",
    "    feedback: Optional[str] = None\n",
    "\n",
    "    def __str__(self):\n",
    "        try:\n",
    "            computed = self.candidate.compute()\n",
    "        except Exception as e:\n",
    "            computed = f\"Invalid equation: {self.candidate.tokens}; Error: {repr(e)}\"\n",
    "\n",
    "        return f\"Equation({self.candidate.tokens}) = {computed} (Reward: {self.score})\"\n",
    "\n",
    "\n",
    "class ScoredCandidate(Candidate):\n",
    "    candidate: Equation\n",
    "    score: float\n",
    "    feedback: str"
   ],
   "id": "802981e89d21474a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Fetch Data\n",
    "\n",
    "We'll use an example from the Game of 24 dataset.\n"
   ],
   "id": "1f59508592ca7764"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:24.174677Z",
     "start_time": "2025-07-02T22:30:23.354221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "csv_data = requests.get(\n",
    "    \"https://storage.googleapis.com/benchmarks-artifacts/game-of-24/24.csv\"\n",
    ").content.decode(\"utf-8\")\n",
    "# Get just the Puzzles column (column index 1)\n",
    "puzzles = [row[1].strip() for row in csv.reader(csv_data.splitlines()[1:])]\n",
    "\n",
    "print(f\"Example puzzles: {puzzles[:3]}\")"
   ],
   "id": "bd5c1874e01a25d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example puzzles: ['1 1 4 6', '1 1 11 11', '1 1 3 8']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Expander\n",
    "\n",
    "The \"tree of thoughts\" algorithm is relatively generic. The primary two task-specific components are the **expander** and the **scorer**. The **expander** (the augmented LLM) tries to generate 1 or more solutions to the problem. On subsequent attempts, it is given a seed/candidate value from the previous search.\n",
    "\n",
    "You can update this section to match your own task requirements. The expander can be arbitrarily complex. All that's required is that it accepts the problem and an optional previous attempt (or attempts) and returns a new result.\n"
   ],
   "id": "ede1a1972d66c8c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:27.511023Z",
     "start_time": "2025-07-02T22:30:24.208554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are playing the Game of 24. Using the provide numbers, create an equation that evaluates to 24.\\n\"\n",
    "            \"Submit exactly {k} guesses for this round.\",\n",
    "        ),\n",
    "        (\"user\", \"Solve the 24 game for these numbers: {problem}.{candidate}\"),\n",
    "    ],\n",
    ").partial(candidate=\"\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "bound_llm = llm.with_structured_output(GuessEquations)\n",
    "solver = prompt | bound_llm"
   ],
   "id": "11bbe3df1240e7c9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scorer\n",
    "\n",
    "In this game, the scorer is easy. We need to assert two things:\n",
    "\n",
    "1. The LLM has generated a valid equation using each number exactly one time.\n",
    "2. The equation evaluates to 24.\n",
    "\n",
    "You can update this function to match your own task requirements.\n"
   ],
   "id": "264822f6c666b9c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:27.540434Z",
     "start_time": "2025-07-02T22:30:27.532692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_score(problem: str, candidate: Candidate) -> ScoredCandidate:\n",
    "    numbers = list(map(int, problem.split()))\n",
    "    # Check that the candidate equation uses all 4 numbers exactly once\n",
    "    used_numbers = [\n",
    "        token for token in candidate.candidate.tokens if isinstance(token, float)\n",
    "    ]\n",
    "    if sorted(used_numbers) != sorted(numbers):\n",
    "        score = 0\n",
    "        feedback = \"The equation must use all 4 numbers exactly once.\"\n",
    "        return ScoredCandidate(\n",
    "            candidate=candidate.candidate, score=score, feedback=feedback\n",
    "        )\n",
    "    try:\n",
    "        result = candidate.candidate.compute()\n",
    "        score = 1 / (1 + abs(24 - result))\n",
    "        feedback = f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        score = 0\n",
    "        feedback = f\"Invalid equation. Error: {repr(e)}\"\n",
    "    return ScoredCandidate(\n",
    "        candidate=candidate.candidate, score=score, feedback=feedback\n",
    "    )"
   ],
   "id": "599595a6261e62",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graph\n",
    "it's time to create our graph."
   ],
   "id": "616a53b5edd9078e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:27.804573Z",
     "start_time": "2025-07-02T22:30:27.621417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import operator\n",
    "from typing import Optional, Dict, Any\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.constants import Send\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "def update_candidates(\n",
    "    existing: Optional[list] = None,\n",
    "    updates: Optional[Union[list, Literal[\"clear\"]]] = None,\n",
    ") -> List[str]:\n",
    "    if existing is None:\n",
    "        existing = []\n",
    "    if updates is None:\n",
    "        return existing\n",
    "    if updates == \"clear\":\n",
    "        return []\n",
    "    # Concatenate the lists\n",
    "    return existing + updates\n",
    "\n",
    "\n",
    "class ToTState(TypedDict):\n",
    "    problem: str\n",
    "    candidates: Annotated[List[Candidate], update_candidates]\n",
    "    scored_candidates: Annotated[List[ScoredCandidate], update_candidates]\n",
    "    depth: Annotated[int, operator.add]\n",
    "\n",
    "\n",
    "class Configuration(TypedDict, total=False):\n",
    "    max_depth: int\n",
    "    threshold: float\n",
    "    k: int\n",
    "    beam_size: int\n",
    "\n",
    "\n",
    "def _ensure_configurable(config: RunnableConfig) -> Configuration:\n",
    "    \"\"\"Get params that configure the search algorithm.\"\"\"\n",
    "    configurable = config.get(\"configurable\", {})\n",
    "    return {\n",
    "        **configurable,\n",
    "        \"max_depth\": configurable.get(\"max_depth\", 10),\n",
    "        \"threshold\": config.get(\"threshold\", 0.9),\n",
    "        \"k\": configurable.get(\"k\", 5),\n",
    "        \"beam_size\": configurable.get(\"beam_size\", 3),\n",
    "    }\n",
    "\n",
    "\n",
    "class ExpansionState(ToTState):\n",
    "    seed: Optional[Candidate]\n",
    "\n",
    "\n",
    "def expand(state: ExpansionState, *, config: RunnableConfig) -> Dict[str, List[str]]:\n",
    "    \"\"\"Generate the next state.\"\"\"\n",
    "    configurable = _ensure_configurable(config)\n",
    "    if not state.get(\"seed\"):\n",
    "        candidate_str = \"\"\n",
    "\n",
    "    else:\n",
    "        candidate_str = \"\\n\\n\" + str(state[\"seed\"])\n",
    "\n",
    "    try:\n",
    "        equation_submission = solver.invoke(\n",
    "            {\n",
    "                \"problem\": state[\"problem\"],\n",
    "                \"candidate\": candidate_str,\n",
    "                \"k\": configurable[\"k\"],\n",
    "            },\n",
    "            config=config,\n",
    "        )\n",
    "    except Exception:\n",
    "        return {\"candidates\": []}\n",
    "    new_candidates = [\n",
    "        Candidate(candidate=equation) for equation in equation_submission.equations\n",
    "    ]\n",
    "    return {\"candidates\": new_candidates}\n",
    "\n",
    "\n",
    "def score(state: ToTState) -> Dict[str, List[float]]:\n",
    "    \"\"\"Evaluate the candidate generations.\"\"\"\n",
    "    candidates = state[\"candidates\"]\n",
    "    scored = []\n",
    "    for candidate in candidates:\n",
    "        scored.append(compute_score(state[\"problem\"], candidate))\n",
    "    return {\"scored_candidates\": scored, \"candidates\": \"clear\"}\n",
    "\n",
    "\n",
    "def prune(\n",
    "    state: ToTState, *, config: RunnableConfig\n",
    ") -> Dict[str, List[Dict[str, Any]]]:\n",
    "    scored_candidates = state[\"scored_candidates\"]\n",
    "    beam_size = _ensure_configurable(config)[\"beam_size\"]\n",
    "    organized = sorted(\n",
    "        scored_candidates, key=lambda candidate: candidate[1], reverse=True\n",
    "    )\n",
    "    pruned = organized[:beam_size]\n",
    "    return {\n",
    "        # Update the starting point for the next iteration\n",
    "        \"candidates\": pruned,\n",
    "        # Clear the old memory\n",
    "        \"scored_candidates\": \"clear\",\n",
    "        # Increment the depth by 1\n",
    "        \"depth\": 1,\n",
    "    }\n",
    "\n",
    "\n",
    "def should_terminate(\n",
    "    state: ToTState, config: RunnableConfig\n",
    ") -> Union[Literal[\"__end__\"], Send]:\n",
    "    configurable = _ensure_configurable(config)\n",
    "    solved = state[\"candidates\"][0].score >= configurable[\"threshold\"]\n",
    "    if solved or state[\"depth\"] >= configurable[\"max_depth\"]:\n",
    "        return \"__end__\"\n",
    "    return [\n",
    "        Send(\"expand\", {**state, \"somevalseed\": candidate})\n",
    "        for candidate in state[\"candidates\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "# Create the graph\n",
    "builder = StateGraph(state_schema=ToTState, config_schema=Configuration)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(expand)\n",
    "builder.add_node(score)\n",
    "builder.add_node(prune)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(\"expand\", \"score\")\n",
    "builder.add_edge(\"score\", \"prune\")\n",
    "builder.add_conditional_edges(\"prune\", should_terminate, path_map=[\"expand\", \"__end__\"])\n",
    "\n",
    "# Set entry point\n",
    "builder.add_edge(\"__start__\", \"expand\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile(checkpointer=MemorySaver())"
   ],
   "id": "4c94faccd6d81e72",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:30:28.541387Z",
     "start_time": "2025-07-02T22:30:27.828221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "709f28991b3487d5",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Run\n",
    "Now let's try it on one of the puzzles!"
   ],
   "id": "984f319e4674efe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:33:09.911786Z",
     "start_time": "2025-07-02T22:33:06.990189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"test_1\",\n",
    "        \"depth\": 10,\n",
    "    }\n",
    "}\n",
    "for step in graph.stream({\"problem\": puzzles[42]}, config):\n",
    "    print(step)"
   ],
   "id": "289b835e7b2d54d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'expand': {'candidates': [Candidate(candidate=Equation(tokens=[12.0, 7.0, '*', 5.0, '-', 1.0, '+']), score=None, feedback=None), Candidate(candidate=Equation(tokens=[12.0, 5.0, '*', 7.0, '-', 1.0, '+']), score=None, feedback=None), Candidate(candidate=Equation(tokens=[5.0, 7.0, '*', 1.0, '+', 12.0, '-']), score=None, feedback=None), Candidate(candidate=Equation(tokens=[12.0, 1.0, '-', 5.0, '*', 7.0, '+']), score=None, feedback=None), Candidate(candidate=Equation(tokens=[7.0, 5.0, '*', 1.0, '+', 12.0, '-']), score=None, feedback=None)]}}\n",
      "{'score': {'scored_candidates': [ScoredCandidate(candidate=Equation(tokens=[7.0, 5.0, '+', 12.0, '+', 1.0, '-']), score=0.5, feedback='Result: 23.0'), ScoredCandidate(candidate=Equation(tokens=[12.0, 1.0, '/', 7.0, '+', 5.0]), score=0.16666666666666666, feedback='Result: 19.0'), ScoredCandidate(candidate=Equation(tokens=[1.0, 12.0, '*', 5.0, '-', 7.0, '+']), score=0.09090909090909091, feedback='Result: 14.0'), ScoredCandidate(candidate=Equation(tokens=[12.0, 7.0, '*', 5.0, '-', 1.0, '+']), score=0.017543859649122806, feedback='Result: 80.0'), ScoredCandidate(candidate=Equation(tokens=[12.0, 5.0, '*', 7.0, '-', 1.0, '+']), score=0.03225806451612903, feedback='Result: 54.0'), ScoredCandidate(candidate=Equation(tokens=[5.0, 7.0, '*', 1.0, '+', 12.0, '-']), score=1.0, feedback='Result: 24.0'), ScoredCandidate(candidate=Equation(tokens=[12.0, 1.0, '-', 5.0, '*', 7.0, '+']), score=0.02564102564102564, feedback='Result: 62.0'), ScoredCandidate(candidate=Equation(tokens=[7.0, 5.0, '*', 1.0, '+', 12.0, '-']), score=1.0, feedback='Result: 24.0')], 'candidates': 'clear'}}\n",
      "{'prune': {'candidates': [ScoredCandidate(candidate=Equation(tokens=[5.0, 7.0, '*', 1.0, '+', 12.0, '-']), score=1.0, feedback='Result: 24.0'), ScoredCandidate(candidate=Equation(tokens=[7.0, 5.0, '*', 1.0, '+', 12.0, '-']), score=1.0, feedback='Result: 24.0'), ScoredCandidate(candidate=Equation(tokens=[7.0, 5.0, '+', 12.0, '+', 1.0, '-']), score=0.5, feedback='Result: 23.0')], 'scored_candidates': 'clear', 'depth': 1}}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:33:12.668509Z",
     "start_time": "2025-07-02T22:33:12.661512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_state = graph.get_state(config)\n",
    "winning_solution = final_state.values[\"candidates\"][0]\n",
    "search_depth = final_state.values[\"depth\"]\n",
    "if winning_solution[1] == 1:\n",
    "    print(f\"Found a winning solution in {search_depth} steps: {winning_solution}\")\n",
    "else:\n",
    "    print(\n",
    "        f\"Failed to find a winning solution in {search_depth} steps. Best guess: {winning_solution}\"\n",
    "    )"
   ],
   "id": "eae14e00d3961138",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a winning solution in 11 steps: Equation([5.0, 7.0, '*', 1.0, '+', 12.0, '-']) = 24.0 (Reward: 1.0)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "Now let's create an evaluation function"
   ],
   "id": "f2fce5a5fbfdf00d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:33:19.693242Z",
     "start_time": "2025-07-02T22:33:19.680262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Dict, Any\n",
    "import statistics\n",
    "\n",
    "def evaluate_tot_llm_performance(results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate LLM performance in Tree of Thoughts runs.\n",
    "\n",
    "    Parameters:\n",
    "        results: A list of dictionaries, each representing the final state from a ToT run.\n",
    "            Each dict should contain:\n",
    "                - \"solved\": bool\n",
    "                - \"depth\": int\n",
    "                - \"best_score\": float\n",
    "                - \"equation\": Equation object or string\n",
    "\n",
    "    Returns:\n",
    "        A summary dictionary with aggregate statistics.\n",
    "    \"\"\"\n",
    "    num_trials = len(results)\n",
    "    num_solved = sum(1 for r in results if r[\"solved\"])\n",
    "    avg_depth = statistics.mean(r[\"depth\"] for r in results)\n",
    "    avg_score = statistics.mean(r[\"best_score\"] for r in results)\n",
    "    max_score = max(r[\"best_score\"] for r in results)\n",
    "\n",
    "    solved_equations = [r[\"equation\"] for r in results if r[\"solved\"]]\n",
    "\n",
    "    return {\n",
    "        \"total_problems\": num_trials,\n",
    "        \"solved_problems\": num_solved,\n",
    "        \"accuracy\": num_solved / num_trials,\n",
    "        \"average_depth\": round(avg_depth, 2),\n",
    "        \"average_best_score\": round(avg_score, 3),\n",
    "        \"highest_score\": round(max_score, 3),\n",
    "        \"solved_equations\": solved_equations,\n",
    "    }"
   ],
   "id": "746b8719a3e1b349",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Gather results from multiple runs\n",
    "Now let's run the ToT on many problem and extract results"
   ],
   "id": "37b18a528e5161c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:38:48.538868Z",
     "start_time": "2025-07-02T22:33:27.702682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_tot_on_problem(problem: str, graph, config) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run Tree of Thoughts on a single Game of 24 problem and extract evaluation-relevant metrics.\n",
    "\n",
    "    Parameters:\n",
    "        problem: A string like \"3 4 6 1\"\n",
    "        graph: Compiled LangGraph object\n",
    "        config: Dict passed to LangGraph nodes\n",
    "\n",
    "    Returns:\n",
    "        A dictionary compatible with evaluation function:\n",
    "        {\n",
    "            \"solved\": bool,\n",
    "            \"depth\": int,\n",
    "            \"best_score\": float,\n",
    "            \"equation\": str\n",
    "        }\n",
    "    \"\"\"\n",
    "    state_input = {\"problem\": problem}\n",
    "\n",
    "    # Run the graph (stream can be skipped if not needed)\n",
    "    for _ in graph.stream(state_input, config):\n",
    "        pass  # progress through the full search\n",
    "\n",
    "    # Get final state\n",
    "    final_state = graph.get_state(config).values\n",
    "    depth = final_state[\"depth\"]\n",
    "    candidates = final_state[\"candidates\"]\n",
    "\n",
    "    # Select best-scoring candidate\n",
    "    best = max(candidates, key=lambda c: c.score)\n",
    "\n",
    "    return {\n",
    "        \"solved\": best.score >= config[\"configurable\"].get(\"threshold\", 0.9),\n",
    "        \"depth\": depth,\n",
    "        \"best_score\": best.score,\n",
    "        \"equation\": str(best.candidate.tokens),\n",
    "        \"feedback\": best.feedback\n",
    "    }\n",
    "\n",
    "\n",
    "def run_tot_on_many_problems(puzzles: List[str], graph, limit: int = 10) -> List[Dict[str, Any]]:\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"eval_batch\",\n",
    "            \"depth\": 10,\n",
    "            \"threshold\": 0.99,  # stricter match for Game of 24\n",
    "            \"k\": 5,\n",
    "            \"beam_size\": 3,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for i, puzzle in enumerate(puzzles[:limit]):\n",
    "        print(f\"Running puzzle {i + 1}: {puzzle}\")\n",
    "        try:\n",
    "            result = run_tot_on_problem(puzzle, graph, config)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error on puzzle {i + 1}: {repr(e)}\")\n",
    "            results.append({\n",
    "                \"solved\": False,\n",
    "                \"depth\": -1,\n",
    "                \"best_score\": 0,\n",
    "                \"equation\": \"ERROR\",\n",
    "                \"feedback\": str(e),\n",
    "            })\n",
    "    return results\n",
    "\n",
    "results = run_tot_on_many_problems(puzzles=puzzles[1:101], graph = graph, limit = 150)\n"
   ],
   "id": "da43c7893a185ced",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running puzzle 1: 1 1 11 11\n",
      "Error on puzzle 1: GraphRecursionError('Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT')\n",
      "Running puzzle 2: 1 1 3 8\n",
      "Running puzzle 3: 1 1 1 8\n",
      "Running puzzle 4: 6 6 6 6\n",
      "Running puzzle 5: 1 1 2 12\n",
      "Running puzzle 6: 1 2 2 6\n",
      "Running puzzle 7: 1 1 10 12\n",
      "Running puzzle 8: 2 2 10 10\n",
      "Running puzzle 9: 1 1 1 12\n",
      "Running puzzle 10: 1 1 2 8\n",
      "Running puzzle 11: 1 1 4 8\n",
      "Running puzzle 12: 1 1 5 8\n",
      "Running puzzle 13: 4 6 11 11\n",
      "Running puzzle 14: 1 1 3 12\n",
      "Running puzzle 15: 2 2 2 12\n",
      "Running puzzle 16: 1 1 4 12\n",
      "Running puzzle 17: 1 1 12 12\n",
      "Running puzzle 18: 3 3 3 8\n",
      "Running puzzle 19: 1 1 2 6\n",
      "Running puzzle 20: 1 1 2 11\n",
      "Running puzzle 21: 1 2 3 4\n",
      "Running puzzle 22: 11 11 12 12\n",
      "Running puzzle 23: 3 7 7 8\n",
      "Running puzzle 24: 1 1 13 13\n",
      "Running puzzle 25: 1 2 4 12\n",
      "Running puzzle 26: 1 1 3 6\n",
      "Running puzzle 27: 1 1 3 9\n",
      "Running puzzle 28: 7 7 12 12\n",
      "Running puzzle 29: 4 6 7 7\n",
      "Running puzzle 30: 1 1 2 13\n",
      "Running puzzle 31: 1 1 5 6\n",
      "Running puzzle 32: 1 1 11 13\n",
      "Running puzzle 33: 1 6 6 12\n",
      "Running puzzle 34: 4 5 12 12\n",
      "Running puzzle 35: 4 6 13 13\n",
      "Running puzzle 36: 12 12 12 12\n",
      "Running puzzle 37: 2 11 11 12\n",
      "Running puzzle 38: 4 4 4 6\n",
      "Running puzzle 39: 1 1 1 11\n",
      "Running puzzle 40: 1 1 11 12\n",
      "Running puzzle 41: 2 7 7 12\n",
      "Running puzzle 42: 1 5 7 12\n",
      "Running puzzle 43: 10 10 12 12\n",
      "Running puzzle 44: 1 8 8 8\n",
      "Running puzzle 45: 2 2 3 8\n",
      "Running puzzle 46: 2 9 9 12\n",
      "Running puzzle 47: 11 11 11 12\n",
      "Running puzzle 48: 3 8 13 13\n",
      "Running puzzle 49: 9 9 12 12\n",
      "Running puzzle 50: 1 1 5 5\n",
      "Running puzzle 51: 3 3 12 12\n",
      "Running puzzle 52: 1 1 4 5\n",
      "Running puzzle 53: 1 6 8 12\n",
      "Running puzzle 54: 8 8 12 12\n",
      "Running puzzle 55: 3 8 11 11\n",
      "Running puzzle 56: 5 6 12 12\n",
      "Running puzzle 57: 11 12 12 12\n",
      "Running puzzle 58: 12 12 13 13\n",
      "Running puzzle 59: 1 1 12 13\n",
      "Running puzzle 60: 1 3 5 12\n",
      "Running puzzle 61: 5 5 12 12\n",
      "Running puzzle 62: 1 9 9 12\n",
      "Running puzzle 63: 2 3 3 12\n",
      "Running puzzle 64: 3 4 4 8\n",
      "Running puzzle 65: 3 8 10 10\n",
      "Running puzzle 66: 3 8 9 9\n",
      "Running puzzle 67: 2 5 5 12\n",
      "Running puzzle 68: 11 11 11 13\n",
      "Running puzzle 69: 2 12 13 13\n",
      "Running puzzle 70: 7 7 11 12\n",
      "Running puzzle 71: 1 1 3 7\n",
      "Running puzzle 72: 1 4 10 10\n",
      "Running puzzle 73: 4 4 12 12\n",
      "Running puzzle 74: 1 3 4 12\n",
      "Running puzzle 75: 5 5 11 12\n",
      "Running puzzle 76: 1 2 5 8\n",
      "Running puzzle 77: 2 2 4 6\n",
      "Running puzzle 78: 1 6 7 12\n",
      "Running puzzle 79: 1 8 9 12\n",
      "Running puzzle 80: 6 7 12 12\n",
      "Running puzzle 81: 1 3 10 10\n",
      "Running puzzle 82: 2 3 3 8\n",
      "Running puzzle 83: 3 5 5 8\n",
      "Running puzzle 84: 1 1 1 13\n",
      "Running puzzle 85: 2 3 12 12\n",
      "Running puzzle 86: 1 4 7 12\n",
      "Running puzzle 87: 8 8 11 13\n",
      "Running puzzle 88: 1 3 3 4\n",
      "Running puzzle 89: 1 8 8 12\n",
      "Running puzzle 90: 3 7 8 8\n",
      "Running puzzle 91: 7 8 12 12\n",
      "Running puzzle 92: 9 9 11 12\n",
      "Running puzzle 93: 1 2 5 12\n",
      "Running puzzle 94: 2 7 7 8\n",
      "Running puzzle 95: 4 4 11 13\n",
      "Running puzzle 96: 1 1 4 7\n",
      "Running puzzle 97: 1 1 10 13\n",
      "Running puzzle 98: 4 6 6 6\n",
      "Running puzzle 99: 5 5 7 7\n",
      "Running puzzle 100: 4 5 11 12\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate Performance\n",
    "Now let's Evaluate the Performance"
   ],
   "id": "761f2ecaf55c1881"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:39:04.051683Z",
     "start_time": "2025-07-02T22:39:04.040499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_tot_llm_performance(results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    num_trials = len(results)\n",
    "    num_solved = sum(1 for r in results if r[\"solved\"])\n",
    "    avg_depth = sum(r[\"depth\"] for r in results if r[\"depth\"] >= 0) / max(1, num_trials)\n",
    "    avg_score = sum(r[\"best_score\"] for r in results) / max(1, num_trials)\n",
    "    max_score = max(r[\"best_score\"] for r in results)\n",
    "\n",
    "    return {\n",
    "        \"total_problems\": num_trials,\n",
    "        \"solved_problems\": num_solved,\n",
    "        \"accuracy\": round(num_solved / num_trials, 3),\n",
    "        \"average_depth\": round(avg_depth, 2),\n",
    "        \"average_best_score\": round(avg_score, 3),\n",
    "        \"highest_score\": round(max_score, 3),\n",
    "        # \"example_solutions\": [r[\"equation\"] for r in results if r[\"solved\"]][:3]\n",
    "        \"example_solutions\": [r[\"equation\"] for r in results if r[\"solved\"]]\n",
    "    }\n",
    "\n",
    "\n",
    "metrics = evaluate_tot_llm_performance(results=results)"
   ],
   "id": "451b9d17235486be",
   "outputs": [],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
